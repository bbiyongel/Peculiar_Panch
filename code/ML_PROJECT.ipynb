{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = numpy.cumsum(numpy.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100001\n"
     ]
    }
   ],
   "source": [
    "def read_file():\n",
    "    feat1 = []\n",
    "    feat2 = []\n",
    "    feat3 = []\n",
    "    feat_all =[]\n",
    "#     arff_file = open(\"train.arff\",\"w\")\n",
    "#     arff_file.write(\"@relation ML_TERM_PROJECT\\n@attribute feat1 numeric\\n@attribute feat2 numeric \\\\\n",
    "#     \\n@attribute feat3 numeric\\n@attribute feat4 numeric\\n@attribute feat5 numeric\\n@attribute feat6 numeric\\n\\\\\n",
    "#     @attribute feat7 numeric\\n@attribute feat8 numeric\\n@attribute feat9 numeric\\n@attribute feat10 numeric\\n\\\\\n",
    "#     @attribute feat11 numeric\\n@attribute feat12 numeric\\n@attribute class {0,1,2,3}\\n\\n@data\\n\")\n",
    "    \n",
    "    with open(\"./ML_data/Residuals_NoFault.txt\") as fp:\n",
    "        for line in fp:\n",
    "            parts = line.split()\n",
    "            feat1.append(float(parts[0].strip()))\n",
    "            feat2.append(float(parts[1].strip()))\n",
    "            feat3.append(float(parts[2].strip()))\n",
    "    feat_all=[feat1,feat2,feat3]\n",
    "    #key_counter = 1\n",
    "    for file_counter in range(1,4):\n",
    "        key_counter = 1\n",
    "        with open(\"./Time_Series/No_Fault_\"+str(file_counter),\"w\") as fp:\n",
    "            line_counter = 1\n",
    "            fp.write(str(key_counter)+\" \")\n",
    "            for item in feat_all[file_counter-1]:\n",
    "                if line_counter%200==0:\n",
    "                    fp.write(\"\\n\"+str(key_counter)+\" \")\n",
    "                    key_counter += 1\n",
    "                fp.write(str(item)+\" \")\n",
    "                line_counter += 1\n",
    "\n",
    "\n",
    "#     feat1_1 = running_mean(feat1,10)\n",
    "#     feat2_1 = running_mean(feat2,10)\n",
    "#     feat3_1 = running_mean(feat3,10)\n",
    "#     print numpy.mean(feat1)\n",
    "#     arff_file.write(str(numpy.mean(feat1))+\",\"+str(numpy.std(feat1))+\",\"+str(numpy.mean(feat2))+\",\"+str(numpy.std(feat2))+\n",
    "#               \",\"+str(numpy.mean(feat3))+\",\"+str(numpy.std(feat3))+\",\")\n",
    "#     arff_file.write(str(numpy.mean(feat1_1))+\",\"+str(numpy.std(feat1_1))+\",\"+str(numpy.mean(feat2_1))+\",\"+str(numpy.std(feat2_1))+\n",
    "#              \",\"+str(numpy.mean(feat3_1))+\",\"+str(numpy.std(feat3_1))+\",0\\n\")\n",
    "    feat1 = []\n",
    "    feat2 = []\n",
    "    feat3 = []\n",
    "    feat_all =[]\n",
    "    \n",
    "    with open(\"./ML_data/Residuals_EMFault.txt\") as fp:\n",
    "        for line in fp:\n",
    "            parts = line.split()\n",
    "            feat1.append(float(parts[0].strip()))\n",
    "            feat2.append(float(parts[1].strip()))\n",
    "            feat3.append(float(parts[2].strip()))\n",
    "            \n",
    "    feat_all=[feat1,feat2,feat3]\n",
    "    #key_counter = 1\n",
    "    for file_counter in range(1,4):\n",
    "        key_counter = 1\n",
    "        with open(\"./Time_Series/EMLeak_Fault_\"+str(file_counter),\"w\") as fp:\n",
    "            line_counter = 1\n",
    "            fp.write(str(key_counter)+\" \")\n",
    "            for item in feat_all[file_counter-1]:\n",
    "                if line_counter%200==0:\n",
    "                    fp.write(\"\\n\"+str(key_counter)+\" \")\n",
    "                    key_counter += 1\n",
    "                fp.write(str(item)+\" \")\n",
    "                line_counter += 1\n",
    "            \n",
    "    \n",
    "#     feat1_1 = running_mean(feat1,10)\n",
    "#     feat2_1 = running_mean(feat2,10)\n",
    "#     feat3_1 = running_mean(feat3,10)\n",
    "#     print numpy.mean(feat1)\n",
    "#     arff_file.write(str(numpy.mean(feat1))+\",\"+str(numpy.std(feat1))+\",\"+str(numpy.mean(feat2))+\",\"+str(numpy.std(feat2))+\n",
    "#               \",\"+str(numpy.mean(feat3))+\",\"+str(numpy.std(feat3))+\",\")\n",
    "#     arff_file.write(str(numpy.mean(feat1_1))+\",\"+str(numpy.std(feat1_1))+\",\"+str(numpy.mean(feat2_1))+\",\"+str(numpy.std(feat2_1))+\n",
    "#              \",\"+str(numpy.mean(feat3_1))+\",\"+str(numpy.std(feat3_1))+\",1\\n\")\n",
    "    feat1 = []\n",
    "    feat2 = []\n",
    "    feat3 = []\n",
    "    feat_all =[]\n",
    "    with open(\"./ML_data/Residuals_IMFault.txt\") as fp:\n",
    "        for line in fp:\n",
    "            parts = line.split()\n",
    "            feat1.append(float(parts[0].strip()))\n",
    "            feat2.append(float(parts[1].strip()))\n",
    "            feat3.append(float(parts[2].strip()))\n",
    "    print len(feat1)\n",
    "    feat_all=[feat1,feat2,feat3]\n",
    "    #key_counter = 1\n",
    "    for file_counter in range(1,4):\n",
    "        key_counter = 1\n",
    "        with open(\"./Time_Series/IM_Fault_\"+str(file_counter),\"w\") as fp:\n",
    "            line_counter = 1\n",
    "            fp.write(str(key_counter)+\" \")\n",
    "            for item in feat_all[file_counter-1]:\n",
    "                if line_counter%200==0:\n",
    "                    fp.write(\"\\n\"+str(key_counter)+\" \")\n",
    "                    key_counter += 1\n",
    "                fp.write(str(item)+\" \")\n",
    "                line_counter += 1\n",
    "            \n",
    "#     feat1_1 = running_mean(feat1,10)\n",
    "#     feat2_1 = running_mean(feat2,10)\n",
    "#     feat3_1 = running_mean(feat3,10)\n",
    "#     print numpy.mean(feat1)\n",
    "#     arff_file.write(str(numpy.mean(feat1))+\",\"+str(numpy.std(feat1))+\",\"+str(numpy.mean(feat2))+\",\"+str(numpy.std(feat2))+\n",
    "#               \",\"+str(numpy.mean(feat3))+\",\"+str(numpy.std(feat3))+\",\")\n",
    "#     arff_file.write(str(numpy.mean(feat1_1))+\",\"+str(numpy.std(feat1_1))+\",\"+str(numpy.mean(feat2_1))+\",\"+str(numpy.std(feat2_1))+\n",
    "#              \",\"+str(numpy.mean(feat3_1))+\",\"+str(numpy.std(feat3_1))+\",2\\n\")\n",
    "\n",
    "    feat1 = []\n",
    "    feat2 = []\n",
    "    feat3 = []\n",
    "    feat_all =[]\n",
    "    \n",
    "    with open(\"./ML_data/Residuals_InjFault.txt\") as fp:\n",
    "        for line in fp:\n",
    "            parts = line.split()\n",
    "            feat1.append(float(parts[0].strip()))\n",
    "            feat2.append(float(parts[1].strip()))\n",
    "            feat3.append(float(parts[2].strip()))\n",
    "    \n",
    "    feat_all=[feat1,feat2,feat3]\n",
    "    \n",
    "    for file_counter in range(1,4):\n",
    "        key_counter = 1\n",
    "        with open(\"./Time_Series/Injector_Fault_\"+str(file_counter),\"w\") as fp:\n",
    "            line_counter = 1\n",
    "            fp.write(str(key_counter)+\" \")\n",
    "            for item in feat_all[file_counter-1]:\n",
    "                if line_counter%200==0:\n",
    "                    fp.write(\"\\n\"+str(key_counter)+\" \")\n",
    "                    key_counter += 1\n",
    "                fp.write(str(item)+\" \")\n",
    "                line_counter += 1\n",
    "            \n",
    "            \n",
    "#     feat1_1 = running_mean(feat1,10)\n",
    "#     feat2_1 = running_mean(feat2,10)\n",
    "#     feat3_1 = running_mean(feat3,10)\n",
    "#     print numpy.mean(feat1)\n",
    "#     arff_file.write(str(numpy.mean(feat1))+\",\"+str(numpy.std(feat1))+\",\"+str(numpy.mean(feat2))+\",\"+str(numpy.std(feat2))+\n",
    "#               \",\"+str(numpy.mean(feat3))+\",\"+str(numpy.std(feat3))+\",\")\n",
    "#     arff_file.write(str(numpy.mean(feat1_1))+\",\"+str(numpy.std(feat1_1))+\",\"+str(numpy.mean(feat2_1))+\",\"+str(numpy.std(feat2_1))+\n",
    "#              \",\"+str(numpy.mean(feat3_1))+\",\"+str(numpy.std(feat3_1))+\",3\\n\")\n",
    "\n",
    "read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8523\n"
     ]
    }
   ],
   "source": [
    "def extract_feature_data():\n",
    "    feature_path = \"./Features/Final_results/\"\n",
    "    temp_counter = 1\n",
    "    feature_matrix = {}\n",
    "    for i in range(0,4381*3):\n",
    "        feature_matrix[i]=[]\n",
    "#     for (dirpath, dirnames, filenames) in walk(feature_path):\n",
    "#         filenames.sort()                   ## This step sorts the feature files in proper order\n",
    "#         first_time = 1\n",
    "#         cur_name = \"\"\n",
    "#         prev_name = \"\"\n",
    "#         loop_counter = 0\n",
    "#         loop_reset = 0\n",
    "#         print \"Files Selected...\"\n",
    "#         for each_f in filenames:\n",
    "#             #print loop_counter\n",
    "#             prev_name = cur_name\n",
    "#             cur_name = each_f.split(\"_\")[0]\n",
    "#             print prev_name,cur_name,loop_counter,loop_reset,\n",
    "#             if first_time == 1:\n",
    "#                 first_time = 0\n",
    "#                 cur_name = each_f.split(\"_\")[0]\n",
    "#                 prev_name = each_f.split(\"_\")[0]\n",
    "#                 loop_reset = 0\n",
    "#             elif cur_name !=prev_name:\n",
    "#                 prev_name = cur_name\n",
    "#                 loop_reset = 0\n",
    "#             else:\n",
    "#                 loop_reset +=4381 \n",
    "#             with open(feature_path+each_f) as fp:\n",
    "#                 for line in fp:\n",
    "#                     #feature_vector = []\n",
    "#                     parts = line.split()\n",
    "#                     #print len(parts)\n",
    "#                     cluster_id = int(parts[0].strip())\n",
    "\n",
    "#                     loop_counter = loop_reset\n",
    "#                     for each_feat in parts[1:]:\n",
    "#                         #feature_vector.append(each_feat.strip())\n",
    "#                         feature_matrix[loop_counter].append(each_feat.strip())\n",
    "#                         loop_counter += 1\n",
    "#                 print loop_counter\n",
    "\n",
    "#                 temp_counter +=1\n",
    "\n",
    "\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in walk(feature_path):\n",
    "        for each_f in filenames:\n",
    "            with open(feature_path+each_f) as fp:\n",
    "                for line in fp:\n",
    "                    #feature_vector = []\n",
    "                    parts = line.split()\n",
    "                    loop_counter = 0\n",
    "                    for each_feat in parts:\n",
    "                        #feature_vector.append(each_feat.strip())\n",
    "                        feature_matrix[loop_counter].append(each_feat.strip())\n",
    "                        loop_counter += 1\n",
    "                #print loop_counter\n",
    "\n",
    "                temp_counter +=1\n",
    "\n",
    "    if 'NaN' in feature_matrix[0]: print \"working\"\n",
    "    selected_feature_num =[]\n",
    "    for key,value in feature_matrix.iteritems():\n",
    "        if value.count('NaN') == 0 and value.count('Inf')==0 and value.count('-Inf') == 0: selected_feature_num.append(key)\n",
    "    print len(selected_feature_num)\n",
    "    #sys.exit(0)\n",
    "    feature_name =[]\n",
    "    with open(\"./Features/Operation_Names.txt\") as fp:\n",
    "        for line in fp:\n",
    "            parts = line.split()\n",
    "            #print parts[2]\n",
    "            feature_name.append(parts[1])\n",
    "            \n",
    "    \n",
    "    with open(\"./matlab_FULL.arff\",\"w\") as fp_feat:\n",
    "        fp_feat.write(\"@RELATION matlab_FULL\\n\")\n",
    "        tec =1\n",
    "        for each_num in selected_feature_num:\n",
    "            fp_feat.write(\"@ATTRIBUTE \"+str(feature_name[each_num%4381])+\"_\"+str(each_num)+\" NUMERIC\\n\")\n",
    "            #fp.write(\"@ATTRIBUTE feat\"+str(tec)+\" NUMERIC\\n\")\n",
    "            tec+=1\n",
    "        fp_feat.write(\"@ATTRIBUTE class {0,1,2,3}\\n\")\n",
    "        fp_feat.write(\"@DATA\\n\")\n",
    "        for (dirpath, dirnames, filenames) in walk(feature_path):\n",
    "            for each_f in filenames:\n",
    "                with open(feature_path+each_f) as fp:\n",
    "                    for line in fp:\n",
    "\n",
    "                        parts = line.split()\n",
    "                        #cluster_id = int(parts[0].strip())\n",
    "                        temp_str=\"\"\n",
    "                        for each_num in selected_feature_num:\n",
    "                            if str(parts[each_num]).strip() in [\"Nan\",\"Inf\",\"-Inf\"] : print \"Wrong\"\n",
    "                            temp_str += str(parts[each_num]).strip()+\",\"   \n",
    "                        if \"EMLeak_Fault\".lower() in each_f.lower():\n",
    "                            fp_feat.write(temp_str+\"1\\n\")\n",
    "                        elif \"IM_Fault\".lower() in each_f.lower():\n",
    "                            fp_feat.write(temp_str+\"2\\n\")\n",
    "                        elif \"Injector_Fault\".lower() in each_f.lower():\n",
    "                            fp_feat.write(temp_str+\"3\\n\")\n",
    "                        elif \"No_Fault\".lower() in each_f.lower():\n",
    "                            fp_feat.write(temp_str+\"0\\n\")\n",
    "                    #for each_num in selected_feature_num:\n",
    "\n",
    "            \n",
    "extract_feature_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_1():\n",
    "    feature_path = \"./Features/Results/\"\n",
    "    output_path =\"./Features/Results_filtered/\"\n",
    "    temp_counter = 1\n",
    "    feature_matrix = {}\n",
    "    for i in range(0,4381*3):\n",
    "        feature_matrix[i]=[]\n",
    "    for (dirpath, dirnames, filenames) in walk(feature_path):\n",
    "        filenames.sort()                   ## This step sorts the feature files in proper order\n",
    "        for each_f in filenames:\n",
    "            res_fp  = open(output_path+each_f,\"w\")\n",
    "            with open(feature_path+each_f) as fp:\n",
    "                for line in fp:\n",
    "                    parts = line.split()\n",
    "\n",
    "                    res_fp.write(' '.join(parts[1:]))\n",
    "                    res_fp.write('\\n')\n",
    "test_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
